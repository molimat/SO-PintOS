
			+--------------------+
			|        CS 140      |
			| PROJECT 1: THREADS |
			|   DESIGN DOCUMENT  |
			+--------------------+
				   
---- GROUP ----

>> Fill in the names and email addresses of your group members.

Matheus Molin <matheusmolin@poli.ufrj.br>
Jonathan Alcantara <email@domain.example>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

			     ALARM CLOCK
			     ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

void check_ticks(struct thread *t, void *aux); /* Function that searchs for tick times on time blocked threads and descreases it each time it verifies. */
int64_t blocked_time; 							/* Blocked time used to put a thread to sleep */

---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

	Foi criado um atributo blocked_time que vai definir por quantos ticks esta thread vai permancer bloqueada.
	Enquanto a thread estiver bloqueada, ela não voltara para a lista de execućao, poupando processamento.
	A medida que o interrupt handler executa, este tambem chama uma funcão foreach que irá controlar o tempo de bloqueio dessas threads.

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

	Ele percorre somente as threads bloqueadas, não precisando passar por todas. Isso ocorre devido a um if presente no check_ticks

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

	A funcão real_time_sleep que é quem controla a chamada da timer_sleep possui uma trava de interrupcão que impede que varias threads possam interromper esse processo.

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

	Não acontece isso pois as interrupcões sao desligadas durante o processo de timer_sleep.

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

	Pela facilidade de implementacão e por ser eficaz com relacão a resolucão do problema de busy-wait. 

			 PRIORITY SCHEDULING
			 ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

/* Funcao que  foi implementada para varrer a lista de ready_threads e comparar suas prioridades. */
	bool compare_priority (const struct list_elem *t,const struct list_elem *e,void *);

/* Sequencia de funcoes que retorna a thread da ready_list com maior prioridade, permitindo que esta thread seja priorizada na execuca0*/
	struct list_elem *higher_priority = list_max (&sema->waiters, compare_priority, NULL); 
	list_remove (higher_priority);
	thread_unblock (higher_priority,struct thread, elem));

/* Ao mudar a prioridade de uma thread, teremos um yield que ira verificar se agora existe uma thread com prioridade maior na lista de espera*/
	void thread_set_priority (int new_priority) 
{
	/* implementado para ter alternância de prioridade momentânea */
		thread_current ()->priority = new_priority;
		struct list_elem *higher_priority_thread = list_max(&ready_list, compare_priority, NULL);
		struct thread *t = list_entry (higher_priority_thread, struct thread, elem);
		if (t->priority > new_priority)
			thread_yield(); //vai verificar se, após adicionar uma nova prioridade, existe uma outra thread de maior prioridade a ser executada antes.
}

/* a cada thread criada verifica-se se esta possui uma prioridade maior do que a thread em execucão, se tiver, ela toma o lugar da thread atual. Foi só adicionado um thread_yield(); */


/* para o Priority Sched, a ideia seria salvar tanto as locks que uma thread tinha, quanto as threads que estao esperando uma determinada lock, para que assim fosse possível trackear as modificaoes 
	O priority donation one está funcionando, acontece que na hora de jogar pras listas eu estive encontrando problemas e nao consegui implementar daí pra frente.
*/
	int highest_priority;
	struct list_elem elem;
	struct list locks_acquired; /* Vai ser a lista de locks que a thread possui */
	struct lock *lock_pending; /* vai conter o ponteiro pra lock pendente para continuar a execucão */
	bool compare_lock_priority (const struct list_elem *e, const struct list_elem *t, void *); /* mais um comparador de prioridade dentro só que dentro da lista de lockers */
	
	if (lock->semaphore.value == 0 && thread_mlfqs == false) {
		struct lock *l = lock;
		if (l->holder->priority < t->priority) {
			l->holder->previous_priority = l->holder->priority;			
			l->holder->priority = t->priority;
		}
	}


>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)

/*
	Essa parte não foi implementada por dificuldades com a programacao e a linguagem.
	A ideia aqui seria de que se uma Thread de prioridade 60, por exemplo estivesse necessitando de uma lock que está com uma prioridade 10, essa lock acabaria ficando travada com a thread de prioridade 10,
	se esta tivesse que esperar uma terceira thread de prioridade 30 executar. Para evitar isso é feito um laco while que vai passando do lock->holder, lock->holder->pending_lock a lock->holder.
	A ideia é percorrer toda a cadeia de locks que estarao suspensas devido a inversão de prioridade e entregar a maior prioridade (que seria a prioridade da thread de 60) para todas as outras threads (a de 		10 e de 30), assim elas poderiam terminar de executar e liberarem a resource.
*/

---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?

/* Na teoria seria usado uma funcao comparadora de locks em cima da lista de threads que estavam aguardando por aquela lock para saber qual era a thread de maior prioridade e assim acorda-la

bool compare_lock_priority (const struct list_elem *e, const struct list_elem *t, void *aux UNUSED) {
	return list_entry(e, struct lock, elem)-> highest_priority < list_entry(t, struct lock, elem) -> highest_priority;
}

Esse processo ocorre com a funcao compare priority que permite verificar as prioridades dentro de uma lista, criando um ponteiro para
a thread de maior prioridade nesta lista. Com isso é possível retirar exatamente esta thread, esteja ela presente na lista de semaforos, ou na lista de threads ready para execucão.

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?

Como foi supracitado, encontrei problemas na manipulacao de listas e isso me impediu de implementar com eficacia tanto a lock_acquire quanto a lock_release.
Mas seguindo a logica proposta, era necessario preencher tres tracks. 
Ao acessar o lock_acquire é verificado se o semaphoro esta liberado, se nao tiver a thread vai armazenar essa lock como pending em sua estrutura. 
Após isso é verificado a thread que tem a lock atualmente, se esta thread tiver uma prioridade menor que a thread que está aguardando, a thread que está aguardando doa sua prioridade para a thread com a lock, para que ela possa executar com mais rapidez. Depois disso, para o ciclo de nested, seria verificado se a thread que possui a lock estava dependendo de outra lock, se tivesse a prioridade desta (que ja
possui a prioridade elevada) doaria para a nova thread e com isso reiniciaria o ciclo recursivo com ponteiros.
Após isso o sema_down seria executado, bloqueando a thread principal. Após o sema_down, se a thread estiver ativa isso quer dizer que já não há mais dependencia do lock, entao o lock_pending é definido como NULL.
Além disso a thread armazena em uma lista interna das locks que ela possui esta nova lock, e eventualmente, se uma nova thread surgir com uma prioridade maior que esta, nessa etapa é feita uma verificacao
das threads que estão aguardando a lock. Se a lista dessas threads possuir alguma thread com a prioridade acima da lock que acabou de pegar a lock, esta thread dá yield.



>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

Na etapa de release as listas e as prioridades precisam ser reestabelecidas. Primeiro removemos a lock da lista de locks que a thread possui. Após isso, se ainda sobra alguma
lock nesta lista, obtemos a lock de maior prioridade, isto é, a lock que possui uma thread aguardando com uma maior prioridade. Se esta prioridade for maior que a thread corrente,
a thread corrente pega a prioridade desta lock. Se não há ninguem na lista, basta conferir qual a prioridade original da thread e recupera-la. 
Para isso voltamos com o  campo previous_priority que foi armazenado anteriormente no lock_acquire.

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

A condicao de corrida se da quando em meio a alteracao de prioridade a funcao é interrompida por alguma outra thread e isso acaba criando inconstancias nas prioridades das threads,
que acabam nao sendo salvas propriamente. Para evitar as questoes de condicao de corrida é possivel desabilitar as interrupcoes enquanto a funcao set_priority estiver ativa, que foi o que foi feito.

Não, pois não são só threads que acessam esta funcao, algumas outras não possuem tratamento para locks e isso impediria estas de acessarem.


---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

/* Seguindo a logica de criar listas que seriam incrementadas com as threads pendentes e as locks de cada thread me pareceu algo bem lógico e simples de manter um regitro das mudanćas nas
prioridades das threadas. Não contava com dificuldades de manipulacao de listas, ainda mais os list_elem, alem da falta de pratica na programacao C.  */

			  ADVANCED SCHEDULER
			  ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0
 4
 8
12
16
20
24
28
32
36

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?

			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

>> Any other comments?
